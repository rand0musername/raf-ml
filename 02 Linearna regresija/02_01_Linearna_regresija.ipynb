{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_01_Linearna_regresija.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "2l-OFjBU_2D6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linearna regresija"
      ]
    },
    {
      "metadata": {
        "id": "jglSyj3pCaKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**\"Linear approach to modelling the relationship between a scalar response and one or more explanatory variables\"**"
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "OFJr40a4_2D8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pregled\n",
        "* Nadgledano učenje\n",
        "* Prosta linearna regresija\n",
        "* Polinomijalna regresija: polinom umesto linearne funkcije\n",
        "* Višestruka linearna regresija: više feature-a\n",
        "  * Hiperravni"
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "id": "05EXY5vB_2D_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Pre svega, import"
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "k-zgX3QE_2EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "id": "nk6vDjq9_2EH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Nadgledano učenje\n",
        "\n",
        "**Nadgledano učenje** (induktivno učenje, supervised learning) se bavi problemima u mašinskom učenju gde treba otkriti vezu između ulaznih i izlaznih podataka tj. \"naučiti\" funkciju koja mapira ulaze na izlaze, na osnovu datog skupa parova $(ulaz, izlaz)$. Tu funkciju nazivamo **hipoteza**. \n",
        "\n",
        "Dva glavna tipa problema su **regresija** (hipoteza je neprekidna funkcija) i **klasifikacija** (hipoteza je diskretna funkcija).\n",
        "\n",
        "[Više o nadgledanom učenju](https://mcerovic.github.io/notes/SupervisedLearning/index.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gvmrlF5S_2EN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linearna regresija\n",
        "\n",
        "* **Linearna regresija** (Linear Regression) je jedna od najpoznatijih metoda nadgledanog učenja\n",
        "* Za početak bavićemo se **prostom** linearnom regresijom  (simple LR, univariate LR)\n",
        "  * Imamo jednu ulaznu promenljivu (**feature**) i jednu izlaznu promenljivu\n",
        "* **Notacija**:\n",
        "  * $x$: Ulazni podaci (features), $x_i$: Ulazni podatak iz i-tog trening uzorka (sempla)\n",
        "  * $y$: Izlazni podaci (labels), $y_i$: Izlazni podatak iz i-tog trening uzorka (sempla)\n",
        "  * $m$: Veličina trening skupa - broj semplova\n",
        "* **Hipoteza (model)**: $ h_\\theta(x) = \\theta_0 + \\theta_1 x $\n",
        "  * Linearna funkcija!\n",
        "  * \"Učimo\" parametre $\\theta_0$ i $\\theta_1$, tj. modifikujemo ih tako da budu \"što bolji\"\n",
        "  * Kako znamo kada su \"bolji\"?\n",
        "* **Funkcija troška** (kriterijumska funkcija, funkcija koštanja, cost function, loss function): **MSE** (srednje kvadratno odstupanje, mean squared error)\n",
        "  * $J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x_i) - y_i)^2$ (nekada $\\frac{1}{2m}$ zbog lepšeg izvoda)\n",
        " * Dakle, menjamo $\\theta_0$ i $\\theta_1$ tako da **minimizujemo** funkciju troška, kako?\n",
        "* **Optimizacija: gradijentni spust** (gradient descent): iterativni optimizacioni metod za minimizaciju funkcije\n",
        "    * Određuje tačno u kom smeru treba da se krećemo da što efikasnije poboljšamo vrednosti parametara\n",
        "    * Varijante: Batch, Minibatch, Stochastic\n",
        "* [Više o linearnoj regresiji](https://mcerovic.github.io/notes/LinearRegression/index.html)\n",
        "* [Više o gradijentnom spustu](https://mcerovic.github.io/notes/GradientDescent/index.html)"
      ]
    },
    {
      "metadata": {
        "id": "95Sfd7ziYXGy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Primer: predviđanje očekivanog životnog veka (OŽV) na osnovu nataliteta\n",
        "\n",
        "Istraživanje od strane World Bank:  [World Development Indicators](https://datacatalog.worldbank.org/dataset/world-development-indicators).\n",
        "\n",
        "[Prateća vizualizacija](https://www.google.com/publicdata/explore?ds=d5bncppjof8f9_&ctype=b&strail=false&nselm=s&met_x=sp_dyn_le00_in&scale_x=lin&ind_x=false&met_y=sp_dyn_tfrt_in&scale_y=lin&ind_y=false&met_s=sp_pop_totl&scale_s=lin&ind_s=false&dimp_c=country:region&ifdim=country&iconSize=0.5&uniSize=0.035#!ctype=b&strail=false&bcs=d&nselm=s&met_x=sp_dyn_le00_in&scale_x=lin&ind_x=false&met_y=sp_dyn_tfrt_in&scale_y=lin&ind_y=false&met_s=sp_pop_totl&scale_s=lin&ind_s=false&dimp_c=country:region&ifdim=country&pit=1421395200000&hl=en_US&dl=en_US&ind=false)\n",
        "\n",
        "Ovo ukazuje na određenu korelaciju (veći natalitet => manji životni vek). Pokušaćemo da kvantifikujemo ovaj odnos tj. da naučimo funkciju $OŽV = f(natalitet)$.\n"
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        },
        "id": "qthAtzts_2EI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mo4SqOpexQoC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Višestruka linearna regresija\n",
        "\n",
        "* **Višestruka linearna regresija** (Multiple Linear Regression, nekad i Multivariate Linear Regression) je ime za linearnu regresiju gde radimo sa više od jednim ulaznim feature-om.\n",
        "* Kao primer radićemo sa datasetom sa sajta **kaggle** pod imenom [**80 cereals**](https://www.kaggle.com/crawford/80-cereals).\n",
        "* Dati su razni podaci o 80 tipova cerealija sa kojima možemo raditi svašta... Recimo da želimo da predvidimo promenljivu **calories** na osnovu promenljivih **fat** i **sugars**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* Dodatna notacija: $x^{(i)}$ je i-ti feature\n",
        "* Hipoteza je sada: $ h_\\theta(x) = bias + w_0 x^{(0)} + w_1 x^{(1)} + ... + w_{n-1} x^{(n-1)} $\n",
        "  * I dalje linearna funkcija samo po više promenlijvih! Umesto fitovanja prave fitujemo ravan tj. hiperravan u određenom broju dimenzija.\n",
        "  * \"Učimo\" parametre $w$!\n",
        "* Funkcija troška ostaje ista, kao i metod optimizacije.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* Kod ćemo pisati generički tako da radi sa bilo kojim brojem feature-a.\n",
        "* Poći ćemo od prethodnog koda.\n"
      ]
    },
    {
      "metadata": {
        "id": "rcZsdP0J1D0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tP9jgYg0x4cb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Polinomijalna regresija\n",
        "\n",
        "* **Polinomijalna regresija** (Polynomial Regression) je naziv za regresiju u kojoj umesto linearne funkcije, učimo polinom nekog stepena.\n",
        "* Izraženo preko višestruke linearne regresije: od stepenova feature-a pravimo nove feature i onda radimo istu proceduru kao u višestrukoj regresiji.\n",
        "* Cela postavka dakle ostaje ista kao u višestrukoj linearnoj regresiji, samo je priprema feature-a drukčija.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Izmenimo primer sa natalitetom i OŽV da podržimo polinome proizvoljnog stepena i posmatrajmo kako to utiče na rezultat."
      ]
    },
    {
      "metadata": {
        "id": "jpARWNk06Ixj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}